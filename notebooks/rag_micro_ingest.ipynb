{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "# RAG — Micro Ingest (PDF → Chunks → JSONL → Embeddings)\n",
    "\n",
    "This notebook is a **smoke test** for our RAG pipeline's text path.\n",
    "You will:\n",
    "1. Verify GPU availability (optional).\n",
    "2. Parse a PDF into clean text **chunks**.\n",
    "3. Save chunks to **JSONL** (`data/processed/<doc_id>.jsonl`).\n",
    "4. Generate **embeddings** for those chunks (GPU if available, otherwise CPU).\n",
    "\n",
    "> Place a sample PDF in `data/raw/` before running **Step 3**.\n"
   ],
   "id": "319cbbed4e9acd5d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T09:41:23.237449Z",
     "start_time": "2025-10-07T09:41:21.498013Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import platform\n",
    "import torch\n",
    "\n",
    "print(\"torch:\", torch.__version__, \"| python:\", platform.python_version())\n",
    "print(\"cuda available:\", torch.cuda.is_available())\n",
    "print(\"torch cuda runtime:\", torch.version.cuda)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"device:\", torch.cuda.get_device_name(0))"
   ],
   "id": "69c01fa67a9b8f72",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.5.1 | python: 3.11.13\n",
      "cuda available: True\n",
      "torch cuda runtime: 12.4\n",
      "device: NVIDIA GeForce RTX 4050 Laptop GPU\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T09:41:23.253419Z",
     "start_time": "2025-10-07T09:41:23.248458Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Path resolution that works from repo root OR notebooks/ ---\n",
    "from pathlib import Path\n",
    "\n",
    "def find_project_root(start: Path, marker: str = \"data\", max_hops: int = 4) -> Path:\n",
    "    \"\"\"Walk upwards from `start` until a folder named `marker` exists.\"\"\"\n",
    "    p = start.resolve()\n",
    "    for _ in range(max_hops):\n",
    "        if (p / marker).exists():\n",
    "            return p\n",
    "        if p.parent == p:\n",
    "            break\n",
    "        p = p.parent\n",
    "    raise FileNotFoundError(f\"Could not find '{marker}/' upwards from {start}\")\n",
    "\n",
    "PROJECT_ROOT = find_project_root(Path.cwd(), marker=\"data\")\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "RAW_DIR  = DATA_DIR / \"raw\"\n",
    "PROC_DIR = DATA_DIR / \"processed\"\n",
    "\n",
    "print(\"project_root :\", PROJECT_ROOT)\n",
    "print(\"data_dir     :\", DATA_DIR)\n",
    "print(\"raw_dir      :\", RAW_DIR)\n",
    "print(\"processed_dir:\", PROC_DIR)\n",
    "\n",
    "# quick sanity check: list PDFs you’ve placed in data/raw\n",
    "pdfs = sorted(RAW_DIR.glob(\"*.pdf\"))\n",
    "print(f\"found {len(pdfs)} pdf(s):\", [p.name for p in pdfs[:5]])"
   ],
   "id": "6a8616a4084137af",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project_root : D:\\Silicon Valley\\Phase 1 - Aug to Sep\\Projects\\3. RAG Chatbot\\RAG_Chatbot\n",
      "data_dir     : D:\\Silicon Valley\\Phase 1 - Aug to Sep\\Projects\\3. RAG Chatbot\\RAG_Chatbot\\data\n",
      "raw_dir      : D:\\Silicon Valley\\Phase 1 - Aug to Sep\\Projects\\3. RAG Chatbot\\RAG_Chatbot\\data\\raw\n",
      "processed_dir: D:\\Silicon Valley\\Phase 1 - Aug to Sep\\Projects\\3. RAG Chatbot\\RAG_Chatbot\\data\\processed\n",
      "found 1 pdf(s): ['sample.pdf']\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T09:43:31.004403Z",
     "start_time": "2025-10-07T09:43:31.000541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Clean text: normalize unicode + collapse whitespace ---\n",
    "import re, unicodedata\n",
    "\n",
    "_WS_RE = re.compile(r\"\\s+\")          # collapse any whitespace run\n",
    "_SOFT_HYPHEN = \"\\u00AD\"              # invisible hyphen inserted in PDFs\n",
    "_BOM = \"\\ufeff\"                      # byte-order mark\n",
    "_NBSP = \"\\u00A0\"                     # non-breaking space\n",
    "\n",
    "def clean_text(s: str) -> str:\n",
    "    if not s:\n",
    "        return \"\"\n",
    "    # remove BOM/soft-hyphen and normalize unicode (compatibility form)\n",
    "    s = s.replace(_BOM, \"\").replace(_SOFT_HYPHEN, \"\")\n",
    "    s = unicodedata.normalize(\"NFKC\", s)\n",
    "    # turn NBSP into a normal space, then collapse whitespace\n",
    "    s = s.replace(_NBSP, \" \")\n",
    "    s = _WS_RE.sub(\" \", s)\n",
    "    return s.strip()"
   ],
   "id": "d4354c7aba0da5a7",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T09:44:09.872774Z",
     "start_time": "2025-10-07T09:44:09.869825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "raw = \"Title\\u00A0 \\n\\n  — Intro\\u00ADduction \\t\\t page 1 \\ufeff\"\n",
    "print(\"RAW:     \", repr(raw))\n",
    "print(\"CLEANED: \", repr(clean_text(raw)))"
   ],
   "id": "2c42c80c92b6fc50",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW:      'Title\\xa0 \\n\\n  — Intro\\xadduction \\t\\t page 1 \\ufeff'\n",
      "CLEANED:  'Title — Introduction page 1'\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T09:47:16.845596Z",
     "start_time": "2025-10-07T09:47:16.840076Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Chunk text into overlapping word windows ---\n",
    "from typing import List\n",
    "\n",
    "CHUNK_MAX_WORDS   = 220   # ~300-350 tokens for MiniLM-like models\n",
    "CHUNK_OVERLAP     = 40    # keep continuity across boundaries\n",
    "MIN_CHUNK_WORDS   = 25    # drop tiny fragments (headers, junk)\n",
    "\n",
    "def chunk_text(text: str,\n",
    "               max_words: int = CHUNK_MAX_WORDS,\n",
    "               overlap: int = CHUNK_OVERLAP,\n",
    "               min_words: int = MIN_CHUNK_WORDS) -> List[str]:\n",
    "\n",
    "    words = text.split()\n",
    "    if not words:\n",
    "        return []\n",
    "    step = max(max_words - overlap, 1)   # avoid infinite loop\n",
    "    chunks, i = [], 0\n",
    "    while i < len(words):\n",
    "        piece = \" \".join(words[i:i+max_words]).strip()\n",
    "        if piece and piece.count(\" \") + 1 >= min_words:\n",
    "            chunks.append(piece)\n",
    "        i += step\n",
    "    return chunks"
   ],
   "id": "378f0d46fb5a572b",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T09:54:50.664797Z",
     "start_time": "2025-10-07T09:54:50.660785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "_demo = (\n",
    "    \"RAG combines retrieval with generation. The retriever fetches relevant passages, \"\n",
    "    \"and the generator (LLM) answers using those passages as grounded context. \"\n",
    "    \"Overlapping windows help preserve coherence near boundaries.\"\n",
    ") * 5  # repeat to force multiple chunks\n",
    "\n",
    "demo_chunks = chunk_text(_demo, max_words=30, overlap=8, min_words=10)\n",
    "print(\"chunks:\", len(demo_chunks))\n",
    "for j, c in enumerate(demo_chunks[:3], 1):\n",
    "    print(f\"[{j}] {c[:90]}...\")"
   ],
   "id": "9c230b8b7c46254e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunks: 6\n",
      "[1] RAG combines retrieval with generation. The retriever fetches relevant passages, and the g...\n",
      "[2] windows help preserve coherence near boundaries.RAG combines retrieval with generation. Th...\n",
      "[3] passages as grounded context. Overlapping windows help preserve coherence near boundaries....\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T10:07:15.888716Z",
     "start_time": "2025-10-07T10:07:15.880729Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import List, Dict, Any\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "\n",
    "def parse_pdf_to_chunks(pdf_path: Path) -> Dict[str, Any]:\n",
    "    \"\"\"Read a PDF and return {'document_id', 'chunks':[...]}.\"\"\"\n",
    "    assert pdf_path.exists(), f\"PDF not found: {pdf_path}\"\n",
    "    import uuid\n",
    "    doc_id = str(uuid.uuid4())\n",
    "\n",
    "    pdf = fitz.open(str(pdf_path))\n",
    "    chunks: List[Dict[str, Any]] = []\n",
    "\n",
    "    for page_idx in range(len(pdf)):\n",
    "        page = pdf.load_page(page_idx)\n",
    "        text = clean_text(page.get_text(\"text\"))\n",
    "        if not text:\n",
    "            # likely scanned; we’ll add OCR later\n",
    "            continue\n",
    "        for part in chunk_text(text):\n",
    "            chunks.append({\n",
    "                \"chunk_id\": str(uuid.uuid4()),\n",
    "                \"document_id\": doc_id,\n",
    "                \"page_no\": page_idx + 1,\n",
    "                \"section_path\": None,   # we’ll fill this when we add heading-aware\n",
    "                \"text\": part,\n",
    "                \"tokens_est\": round(len(part.split()) * 1.33),\n",
    "            })\n",
    "    return {\"document_id\": doc_id, \"chunks\": chunks}"
   ],
   "id": "1d58952f62afe175",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T10:09:32.098039Z",
     "start_time": "2025-10-07T10:09:32.088732Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# pick first PDF in data/raw or set PDF_PATH explicitly\n",
    "pdfs = sorted(RAW_DIR.glob(\"*.pdf\"))\n",
    "assert pdfs, \"No PDFs in data/raw. Add one and re-run.\"\n",
    "PDF_PATH = pdfs[0]\n",
    "record = parse_pdf_to_chunks(PDF_PATH)\n",
    "\n",
    "print(\"document_id:\", record[\"document_id\"], \"| total chunks:\", len(record[\"chunks\"]))\n",
    "print(\"sample chunk ->\")\n",
    "print(record[\"chunks\"][0][\"text\"], \"...\")"
   ],
   "id": "9a05057c037451c5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document_id: d697a0be-041a-4cfb-8957-353df6e320c3 | total chunks: 6\n",
      "sample chunk ->\n",
      "WORK EXPERIENCE  Upwork & Fiverr - Remote (Part-Time) Freelance Data Scientist - [ 09/2021 – Current ] • For Humans (Germany): Architected a fully automated Shopify analytics pipeline (Python, Pandas, Streamlit) that ingests daily sales data, calculates 15+ KPIs (CLV, CAC, repeat rate), and delivers real-time interactive dashboards—slashing report generation time by 90% and empowering data-driven product decisions. • Auto Finance Canada (Canada): Designed and deployed an automated data integrity system (Python, Google Sheets API) for over 10M customer records. The system utilized machine learning-based anomaly detection alongside rule-based validation, reducing manual data preparation by 80% while ensuring regulatory compliance. • MaineWorks & YourModernAccountant: Developed advanced Power-BI & Looker Studio dashboards (SQL , Python) to monitor workforce reintegration success metrics and financial KPIs—boosting reporting efficienc y by 75%, uncovering actionable insights, and driving repeat engagements. • Trusted by 150+ international clients for end-to-end data science solutions ( ETL, predictive analytics, forecasting, visualization), earning top-rated status and consistent 5-star feedback for delivering measurable business impact.  MECHESOL CO - Hybrid (Full-Time) – Multan, Pakistan City: Multan | Country: Pakistan Machine Learning Engineer - [ 07/2022 – 01/09/2025 ] • Developed and launched an internal NLP-powered chatbot to serve as a technical knowledge base for 50+ engineers. The system parsed thousands of pages of technical documents (BOMs, spec sheets), enabling efficient ...\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T10:13:42.380227Z",
     "start_time": "2025-10-07T10:13:42.374670Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "def write_chunks_jsonl(record, out_dir: Path = PROC_DIR) -> Path:\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    out_path = out_dir / f\"{record['document_id']}.jsonl\"\n",
    "    with out_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        for ch in record[\"chunks\"]:\n",
    "            f.write(json.dumps(ch, ensure_ascii=False) + \"\\n\")\n",
    "    return out_path\n",
    "\n",
    "out_path = write_chunks_jsonl(record)\n",
    "print(\"wrote:\", out_path)"
   ],
   "id": "34f7e23485dfa3d0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote: D:\\Silicon Valley\\Phase 1 - Aug to Sep\\Projects\\3. RAG Chatbot\\RAG_Chatbot\\data\\processed\\d697a0be-041a-4cfb-8957-353df6e320c3.jsonl\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9ba36bbd7d34a945"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "98bfbf3d0c54f6e3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2b22d4d0d3d53bc1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "bf7877c77be628ca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "883f85d2e1440067"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c1a1984c3023ca80"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "718956182ca7b655"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f58ee36bac4aba3c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "741504765ce16ac9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "efb79c8963e475c5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "da86f743fc007ae9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
