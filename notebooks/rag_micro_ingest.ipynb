{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "# RAG — Micro Ingest (PDF → Chunks → JSONL → Embeddings)\n",
    "\n",
    "This notebook is a **smoke test** for our RAG pipeline's text path.\n",
    "You will:\n",
    "1. Verify GPU availability (optional).\n",
    "2. Parse a PDF into clean text **chunks**.\n",
    "3. Save chunks to **JSONL** (`data/processed/<doc_id>.jsonl`).\n",
    "4. Generate **embeddings** for those chunks (GPU if available, otherwise CPU).\n",
    "\n",
    "> Place a sample PDF in `data/raw/` before running **Step 3**.\n"
   ],
   "id": "319cbbed4e9acd5d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T08:37:55.442778Z",
     "start_time": "2025-10-07T08:37:53.800036Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import platform\n",
    "try:\n",
    "    import torch\n",
    "    print(\"torch:\", torch.__version__, \"| python:\", platform.python_version())\n",
    "    print(\"cuda available:\", torch.cuda.is_available())\n",
    "    print(\"torch cuda runtime:\", torch.version.cuda)\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"device:\", torch.cuda.get_device_name(0))\n",
    "except Exception as e:\n",
    "    print(\"PyTorch not available in this environment:\", e)"
   ],
   "id": "69c01fa67a9b8f72",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.5.1 | python: 3.11.13\n",
      "cuda available: True\n",
      "torch cuda runtime: 12.4\n",
      "device: NVIDIA GeForce RTX 4050 Laptop GPU\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T08:42:16.444321Z",
     "start_time": "2025-10-07T08:42:16.435813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os, re, uuid, json, time\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "import fitz  # PyMuPDF\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "DATA_DIR = Path(\"../data\")\n",
    "RAW_DIR = DATA_DIR / \"raw\"\n",
    "PROC_DIR = DATA_DIR / \"processed\"\n",
    "PROC_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def clean_text(s: str) -> str:\n",
    "    \"\"\"Normalize whitespace and strip leading/trailing spaces.\"\"\"\n",
    "    return re.sub(r\"\\s+\", \" \", s or \"\").strip()\n",
    "\n",
    "def chunk_text(text: str, max_words: int = 220, overlap: int = 40) -> List[str]:\n",
    "    \"\"\"Split text into slightly overlapping word windows.\"\"\"\n",
    "    words = text.split()\n",
    "    chunks, i = [], 0\n",
    "    step = max(max_words - overlap, 1)\n",
    "    while i < len(words):\n",
    "        chunks.append(\" \".join(words[i:i+max_words]))\n",
    "        i += step\n",
    "    return [c for c in chunks if c.strip()]\n",
    "\n",
    "def parse_pdf_to_chunks(pdf_path: Path) -> Dict[str, Any]:\n",
    "    \"\"\"Read a PDF and return {doc_id, chunks(list of dicts)}.\"\"\"\n",
    "    assert pdf_path.exists(), f\"PDF not found: {pdf_path}\"\n",
    "    doc_id = str(uuid.uuid4())\n",
    "    pdf = fitz.open(str(pdf_path))\n",
    "    chunks: List[Dict[str, Any]] = []\n",
    "    for page_idx in range(len(pdf)):\n",
    "        page = pdf.load_page(page_idx)\n",
    "        text = clean_text(page.get_text(\"text\"))\n",
    "        if not text:\n",
    "            # Scanned page (no text) — OCR will be added later\n",
    "            continue\n",
    "        for part in chunk_text(text):\n",
    "            chunks.append({\n",
    "                \"chunk_id\": str(uuid.uuid4()),\n",
    "                \"document_id\": doc_id,\n",
    "                \"page_no\": page_idx + 1,\n",
    "                \"section_path\": None,\n",
    "                \"text\": part,\n",
    "                \"tokens_est\": round(len(part.split()) * 1.33),\n",
    "            })\n",
    "    return {\"document_id\": doc_id, \"chunks\": chunks}\n",
    "\n",
    "def write_chunks_jsonl(record: Dict[str, Any], out_dir: Path = PROC_DIR) -> Path:\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    out_path = out_dir / f\"{record['document_id']}.jsonl\"\n",
    "    with out_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        for ch in record[\"chunks\"]:\n",
    "            f.write(json.dumps(ch, ensure_ascii=False) + \"\\n\")\n",
    "    return out_path\n",
    "\n",
    "def embed_jsonl(jsonl_path: Path, model_name: str = \"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "    device = \"cuda\"\n",
    "    try:\n",
    "        import torch\n",
    "        if not torch.cuda.is_available():\n",
    "            device = \"cpu\"\n",
    "    except Exception:\n",
    "        device = \"cpu\"\n",
    "    model = SentenceTransformer(model_name, device=device)\n",
    "    texts = []\n",
    "    with jsonl_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            obj = json.loads(line)\n",
    "            texts.append(obj[\"text\"])\n",
    "    vecs = model.encode(texts, batch_size=64, normalize_embeddings=True, convert_to_numpy=True)\n",
    "    print(f\"Embeddings shape: {vecs.shape} | device: {device}\")\n",
    "    return vecs"
   ],
   "id": "6a8616a4084137af",
   "outputs": [],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
